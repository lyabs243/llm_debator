{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2275c7",
   "metadata": {},
   "source": [
    "## Conversational Requests\n",
    "Interaction with contents and systems prompts using one model or combination of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0018ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db24887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init models names\n",
    "GPT_4_1_MINI = \"gpt-4.1-mini\"\n",
    "GPT_4_1 = \"gpt-4.1\"\n",
    "GPT_5_MINI = \"gpt-5-mini\"\n",
    "GPT_5 = \"gpt-5\"\n",
    "\n",
    "GEMINI_2_5_FLASH = \"gemini-2.5-flash\"\n",
    "GEMINI_2_5_PRO = \"gemini-2.5-pro\"\n",
    "\n",
    "GROQ_LLAMA_3_1 = \"llama-3.1-8b-instant\"\n",
    "GROQ_LLAMA_3_3 = \"`llama-3.3-70b-versatile\"\n",
    "GROQ_GPT_OSS_20 = \"openai/gpt-oss-20b\"\n",
    "GROQ_GPT_OSS_120 = \"openai/gpt-oss-120b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1d89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init api keys\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ca8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init clients\n",
    "openai_client = OpenAI()\n",
    "\n",
    "gemini_client = OpenAI(\n",
    "    api_key=gemini_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "groq_client = OpenAI(\n",
    "    api_key=groq_api_key,\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8aea0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(client: OpenAI, model: str, message: str, messages: list[dict]) -> tuple[str|None, list[dict]]:\n",
    "    \"\"\"\n",
    "    Send a message to the specified model using the provided OpenAI client.\n",
    "\n",
    "    Args:\n",
    "        client (OpenAI): The OpenAI client to use for the request.\n",
    "        model (str): The model name to use for the request.\n",
    "        message (str): The user message to send.\n",
    "        messages (list[dict]): The conversation history.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str|None, list[dict]]: The model's response and the updated conversation history.\n",
    "    \"\"\"\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending message: {e}\")\n",
    "    return answer, messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e82d7a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_messages = []\n",
    "gemini_messages = []\n",
    "groq_messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a3962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Loic! Of course, I’d be happy to help. What do you need assistance with today?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, openai_messages = send_message(\n",
    "    client=openai_client,\n",
    "    model=GPT_4_1,\n",
    "    message=\"Hello, my name is Loic. Can you help me?\",\n",
    "    messages=openai_messages,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c14dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, your name is Loic! How can I assist you further?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, openai_messages = send_message(\n",
    "    client=openai_client,\n",
    "    model=GPT_4_1,\n",
    "    message=\"Do you remember my name?\",\n",
    "    messages=openai_messages\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e615623e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hello, my name is Loic. Can you help me?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Hello Loic! Of course, I’d be happy to help. What do you need assistance with today?'},\n",
       " {'role': 'user', 'content': 'Do you remember my name?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Yes, your name is Loic! How can I assist you further?'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23483d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_debator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
